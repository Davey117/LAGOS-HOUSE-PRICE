{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "def scrape_propertypro_production(target_count=10000):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        \"Referer\": \"https://www.google.com/\"\n",
    "    }\n",
    "    \n",
    "    # Approx 20 listings per page,\n",
    "    est_pages = target_count // 20 \n",
    "    print(f\"Starting Large Scale Scrape. Aiming for {target_count} listings (~{est_pages} pages).\")\n",
    "    \n",
    "    csv_filename = \"propertypro_lagos_10k.csv\"\n",
    "    total_scraped = 0\n",
    "    \n",
    "    # If file exists, delete it so we start fresh\n",
    "    if os.path.exists(csv_filename):\n",
    "        os.remove(csv_filename)\n",
    "        \n",
    "    for page in range(1, est_pages + 1):\n",
    "        url = f\"https://www.propertypro.ng/property-for-sale/in/lagos?page={page}\"\n",
    "        \n",
    "        try:\n",
    "            # Random delay to look human (2 to 5 seconds)\n",
    "            time.sleep(random.uniform(2, 5)) \n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Page {page} failed. Status: {response.status_code}\")\n",
    "                continue\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            listings = soup.find_all('div', class_='property-listing')\n",
    "            \n",
    "            if not listings:\n",
    "                print(f\"Page {page} was empty. Stopping early.\")\n",
    "                break\n",
    "\n",
    "            page_data = []\n",
    "            \n",
    "            for card in listings:\n",
    "                try:\n",
    "                    title_div = card.find('div', class_='pl-title')\n",
    "                    if not title_div: continue\n",
    "                    title = title_div.find('h3').text.strip()\n",
    "                    link = \"https://propertypro.ng\" + title_div.find('a')['href']\n",
    "                    location = title_div.find('p').text.strip()\n",
    "                    \n",
    "                    price_div = card.find('div', class_='pl-price')\n",
    "                    price_raw = price_div.find('h3').text.strip()\n",
    "                    features_text = price_div.find('h6').text.strip()\n",
    "                    \n",
    "                    # Regex to extract numbers\n",
    "                    numbers = re.findall(r'\\d+', features_text)\n",
    "                    beds = numbers[0] if len(numbers) >= 1 else 0\n",
    "                    baths = numbers[1] if len(numbers) >= 2 else 0\n",
    "\n",
    "                    page_data.append({\n",
    "                        \"Title\": title,\n",
    "                        \"Location\": location,\n",
    "                        \"Price\": price_raw,\n",
    "                        \"Bedrooms\": beds,\n",
    "                        \"Bathrooms\": baths,\n",
    "                        \"URL\": link\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Append this page's data to the CSV immediately\n",
    "            if page_data:\n",
    "                df = pd.DataFrame(page_data)\n",
    "                # If file doesn't exist, write header. If it does, skip header.\n",
    "                header = not os.path.exists(csv_filename)\n",
    "                df.to_csv(csv_filename, mode='a', header=header, index=False)\n",
    "                \n",
    "                total_scraped += len(page_data)\n",
    "                print(f\"Page {page}/{est_pages} done. Total: {total_scraped} houses.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on page {page}: {e}\")\n",
    "            time.sleep(10) # Wait longer if there is an error\n",
    "            \n",
    "    print(f\"DONE! Saved {total_scraped} listings to {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set this to 10000 when you are ready to let it run for ~1 hour\n",
    "    scrape_propertypro_production(target_count=5000)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
